{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.corpora import Dictionary\n",
    "from biohasher import Biohasher\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_file = '../data/synapses/OWT_hid_400_W_11_LR_0.0002_14.npy'\n",
    "tokenizer_file = '../data/tokenizer/gensim1_patched.dict'\n",
    "stopword_file = '../data/tokenizer/exceptional_ids_terrier_stop.npy'\n",
    "idx_order_file = \"../data/indices_of_memories_Ben.npy\"\n",
    "normalize_synapses = True\n",
    "biohasher = Biohasher(synapse_file, tokenizer_file, stopword_file=stopword_file, normalize_synapses=normalize_synapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memidxs = np.load(idx_order_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memidxs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biohasher.synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_voc=20000\n",
    "N=2*N_voc\n",
    "hid=400\n",
    "prec=1.0e-32\n",
    "p=2\n",
    "\n",
    "synapses=np.load('../data/synapses/OWT_hid_400_W_11_LR_0.0002_14.npy')\n",
    "print(synapses.shape, N)\n",
    "\n",
    "def normalize(syn):\n",
    "    [K,N]=syn.shape\n",
    "    nc=np.power(np.sum(syn**p,axis=1),1/p).reshape(K,1)\n",
    "    syn=syn/np.tile(nc+prec,(1,N))\n",
    "    return syn\n",
    "\n",
    "synapses=normalize(synapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOC = Dictionary.load('/REMOTE/OpenWebText/models/gensim1_patched.dict')\n",
    "VOC = Dictionary.load('../data/tokenizer/gensim1_patched.dict')\n",
    "exceptional_tokens=np.load('../data/tokenizer/exceptional_ids_terrier_stop.npy')    \n",
    "\n",
    "N_VOC=len(VOC)\n",
    "print(N_VOC)\n",
    "\n",
    "tok2id={}\n",
    "for i in range(N_VOC):\n",
    "    tok2id[VOC[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase = 'boat on the bank of the river'\n",
    "#phrase = 'apple latest iphone'\n",
    "#phrase = 'money in bank checking account'\n",
    "#phrase = 'the company stock is training high'\n",
    "#phrase = 'sweet crispy apple pie'\n",
    "phrase = 'But that dialogue did not reflect the state of her marriage Kidman told the magazine'\n",
    "#phrase = 'nation senior military leaders should quarantine after they were advised that Admiral Charles Ray with whom they had met with at a Pentagon meeting had tested positive for the virus'\n",
    "#phrase = 'my research focuses on the computational properties of neural networks'\n",
    "#phrase = 'trump administration campaign rally in oklahoma'\n",
    "#phrase = 'ibm corporation to acquire opensource software startup'\n",
    "#phrase = 'local government officials responded promptly to protests'\n",
    "#phrase = 'influenza virus outbreak in public schools'\n",
    "\n",
    "# Tokenize the phrase\n",
    "v = np.zeros((N,1))\n",
    "for w in phrase.split(' '):\n",
    "    w = w.lower()\n",
    "    if w in tok2id.keys():\n",
    "        print(w, tok2id[w], tok2id[w] not in exceptional_tokens)\n",
    "        if tok2id[w] not in exceptional_tokens:\n",
    "            v[tok2id[w],0] = 1.\n",
    "        \n",
    "        \n",
    "        \n",
    "print(np.nonzero(v))        \n",
    "nc = np.sqrt(np.sum(v*v))\n",
    "v = v/nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.array, beta=1.0):\n",
    "    v = np.exp(beta*x)\n",
    "    return v / np.sum(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_head_contribution(ind_head, beta=10.0, beta_tar=800.0, beta_con=10.0, force_mem=True):\n",
    "    OV = np.dot(synapses,v)\n",
    "    SM = softmax(OV, beta)\n",
    "    mem_ordered = np.argsort(-SM[:,0])\n",
    "    if force_mem:\n",
    "        head = ind_head\n",
    "    else:\n",
    "        head = mem_ordered[ind_head]\n",
    "    print(\"Displaying results for head: \", head)\n",
    "    print('Contribution of the chosen head', 100*SM[head,0])\n",
    "\n",
    "\n",
    "    RHS_tar= synapses[head,N_voc:]\n",
    "    RHS_con= synapses[head,:N_voc]\n",
    "\n",
    "    Z_out = np.sum(np.exp(beta_tar*RHS_tar))\n",
    "    RHS_tar_norm = np.exp(beta_tar*RHS_tar)/Z_out\n",
    "\n",
    "    N_show = 20\n",
    "    print('\\nTARGET')\n",
    "    for ID in np.argsort(-RHS_tar_norm)[:N_show]:\n",
    "        print(ID, VOC[ID], int(ID) not in exceptional_tokens, 100*RHS_tar_norm[ID])\n",
    "\n",
    "    Z_out = np.sum(np.exp(beta_con*RHS_con))\n",
    "    RHS_con_norm = np.exp(beta_con*RHS_con)/Z_out\n",
    "\n",
    "    N_show = 20\n",
    "    print('\\nCONTEXT')\n",
    "    for ID in np.argsort(-RHS_con_norm)[:N_show]:\n",
    "        print(ID, VOC[ID], 100*RHS_con_norm[ID])\n",
    "\n",
    "interact(show_head_contribution, \n",
    "         ind_head=widgets.BoundedIntText(\n",
    "            value=7,\n",
    "            min=0,\n",
    "            max=biohasher.n_heads-1,\n",
    "            step=1,\n",
    "            description='Which head_ind:',\n",
    "            disabled=False\n",
    "        ),\n",
    "#          ind_head=widgets.IntSlider(min=0, max=400, step=1, value=0), \n",
    "         beta=widgets.FloatSlider(min=0.05, max=20.0, step=0.2, value=10.0),\n",
    "         beta_tar=widgets.FloatSlider(min=10, max=1000.0, step=20, value=800.0),\n",
    "         beta_con=widgets.FloatSlider(min=0.5, max=50, step=2, value=10),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 10.0\n",
    "OV = np.dot(synapses,v)\n",
    "Z = np.sum(np.exp(beta*OV))\n",
    "SM = np.exp(beta*OV)/Z\n",
    "mem_ordered = np.argsort(-SM[:,0])\n",
    "\n",
    "ind_head = 1\n",
    "print('Contribution of the chosen head', 100*SM[mem_ordered[ind_head],0])\n",
    "\n",
    "RHS_tar= synapses[mem_ordered[ind_head],N_voc:]\n",
    "# RHS_tar= synapses[ind_head,N_voc:]\n",
    "RHS_con= synapses[mem_ordered[ind_head],:N_voc]\n",
    "\n",
    "beta_out_tar = 800.0\n",
    "Z_out = np.sum(np.exp(beta_out_tar*RHS_tar))\n",
    "RHS_tar_norm = np.exp(beta_out_tar*RHS_tar)/Z_out\n",
    "\n",
    "N_show = 20\n",
    "print('TARGET')\n",
    "for ID in np.argsort(-RHS_tar_norm)[:N_show]:\n",
    "    print(ID, VOC[ID], int(ID) not in exceptional_tokens, 100*RHS_tar_norm[ID])\n",
    "\n",
    "beta_out_con = 10.0\n",
    "Z_out = np.sum(np.exp(beta_out_con*RHS_con))\n",
    "RHS_con_norm = np.exp(beta_out_con*RHS_con)/Z_out\n",
    "    \n",
    "N_show = 20\n",
    "print('CONTEXT')\n",
    "for ID in np.argsort(-RHS_con_norm)[:N_show]:\n",
    "    print(ID, VOC[ID], int(ID) not in exceptional_tokens, 100*RHS_con_norm[ID])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biohasher.get_mem_concepts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(x=True, y=1.0)\n",
    "def g(x, y):\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 21*21 - 2\n",
    "a = np.arange(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "row_len = int(np.ceil(np.sqrt(H)))\n",
    "out = []\n",
    "arr = list(range(H))\n",
    "while idx < H:\n",
    "    out.append(arr[idx: idx + row_len])\n",
    "    idx = idx + row_len\n",
    "print(len(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flybrain] *",
   "language": "python",
   "name": "conda-env-flybrain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
